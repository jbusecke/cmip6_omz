{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7692dd94",
   "metadata": {},
   "source": [
    "# Preprocessing for analyzing CMIP6 OMZ data in oxygen coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2a95db",
   "metadata": {},
   "source": [
    "## What is blocking this?\n",
    "\n",
    "- the new cmip6_pp masking would make this a lot easier (with the labels)\n",
    "\n",
    "\n",
    "## General notes\n",
    "- CM4 is not working due to the wonky chunks. Ill try to squeeze it through anyways, because I do not want to invest much more work here. This will all work better in the cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961d309d",
   "metadata": {},
   "source": [
    "- [x] Make sure to not add 'other variables' (MIROC has a ton of ðŸ’© in there).\n",
    "- [x] 10 deg lat bins\n",
    "- [x] Build in check that zarr file has been written completely\n",
    "- [x] Refine the o2_bins\n",
    "    - [x] seperate the negative bin\n",
    "    - [x] outer bin to 1e5 mymol/kg to get the full ocean volume  \n",
    "- [x]  Masking\n",
    "    - [x] Split Arabian/Bob\n",
    "    - [x] Give flag values (basin names) as attrs(actually as dimension label)\n",
    "    - [x] Only put out the major basins\n",
    "- [x] `o2_bin` data in `mumol/kg`\n",
    "    - [x] check the attrs\n",
    "    - [x] convert them to integers\n",
    "- [x] Add bounds as a coordinate\n",
    "\n",
    "- [x] Make sure to carry the original lev_bounds or dz\n",
    "- [x] Rename 'count' to 'bin_count'\n",
    "- [x] Make sure the variables are properly masked with regards to nans in o2 (needs to be a perfect overlay)\n",
    "- [ ] Maybe resave as nc, but for sure rechunk to larger chunks.\n",
    "- [x] Make sure to reprocess from netcdf\n",
    "- [ ] Dont combine experiments\n",
    "- [ ] Include the other members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd65c5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cf_xarray\n",
    "import intake\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "from cmip6_preprocessing.utils import cmip6_dataset_id\n",
    "from cmip6_preprocessing.preprocessing import combined_preprocessing\n",
    "from cmip6_preprocessing.postprocessing import (\n",
    "    match_metrics,\n",
    "    interpolate_grid_label,\n",
    "    merge_variables,\n",
    "    concat_experiments,\n",
    ")\n",
    "\n",
    "from cmip6_preprocessing.drift_removal import match_and_remove_trend\n",
    "from fastprogress.fastprogress import progress_bar\n",
    "\n",
    "from xhistogram.xarray import histogram\n",
    "\n",
    "from cmip6_omz.utils import cmip6_collection, o2_models\n",
    "from cmip6_omz.upstream_stash import (\n",
    "    pick_first_member,\n",
    "    construct_static_dz,\n",
    "    concat_time,\n",
    "    zarr_exists,\n",
    "    pick_first_member,\n",
    ")\n",
    "from cmip6_omz.units import convert_mol_m3_mymol_kg\n",
    "\n",
    "from xarrayutils.file_handling import maybe_create_folder\n",
    "\n",
    "### needs cleaning\n",
    "from cmip6_omz.omz_tools import omz_thickness_efficient\n",
    "import matplotlib.pyplot as plt\n",
    "from cmip6_omz.upstream_stash import append_write_zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e70ad7",
   "metadata": {},
   "source": [
    "## Start the processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edf9381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v2.3'\n",
    "ofolder = maybe_create_folder(f'/projects/GEOCLIM/LRGROUP/jbusecke/projects_data/cmip6_depth_histogram_{version}')\n",
    "ofolder_control =  maybe_create_folder(f'/projects/GEOCLIM/LRGROUP/jbusecke/projects_data/cmip6_depth_histogram_control_{version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5273de86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# o2_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a570cb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe size before picking latest version: 2280\n",
      "Getting latest version...\n",
      "\n",
      "Dataframe size after picking latest version: 2258\n",
      "\n",
      "Done....\n",
      "\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.member_id.table_id.variable_id.grid_label.dcpp_init_year.version.time_range.path'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3373' class='' max='3373' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3373/3373 17:57<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.member_id.table_id.variable_id.grid_label.dcpp_init_year.version.time_range.path'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1275' class='' max='1275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1275/1275 06:28<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "col = cmip6_collection(zarr=False)\n",
    "kwargs = dict(\n",
    "    aggregate=False,\n",
    "    zarr_kwargs={\"decode_times\": True, \"use_cftime\": True, \"consolidated\": True},\n",
    "    cdf_kwargs={\"decode_times\": True, \"use_cftime\": True, \"chunks\": {\"time\": 1}},\n",
    "    preprocess=combined_preprocessing,\n",
    ")\n",
    "\n",
    "variable_ids = [\"thetao\", \"so\", \"o2\", \"agessc\"]  # \"mlotst\"\n",
    "# variable_ids = [\"o2\", \"agessc\"]\n",
    "metric_variable_ids = [\"thkcello\", \"areacello\"]  # \"mlotst\"\n",
    "\n",
    "# models = o2_models()\n",
    "models = [\n",
    "#         'ACCESS-ESM1-5', # all members done\n",
    "#         'CanESM5',\n",
    "#         'CanESM5-CanOE',\n",
    "#         'CNRM-ESM2-1',\n",
    "#         'IPSL-CM6A-LR',\n",
    "#         'MIROC-ES2L',\n",
    "        'UKESM1-0-LL',\n",
    "        'MPI-ESM1-2-HR',\n",
    "        'MPI-ESM1-2-LR',\n",
    "        'MRI-ESM2-0',\n",
    "        'NorESM2-LM',\n",
    "        'NorESM2-MM',\n",
    "#         \"GFDL-CM4\",\n",
    "#         \"GFDL-ESM4\",\n",
    "]\n",
    "\n",
    "cat = col.search(\n",
    "    source_id=models,\n",
    "    grid_label=[\"gr\", \"gn\"],\n",
    "    experiment_id=[\"historical\", \"ssp585\"],\n",
    "    table_id=[\"Omon\"],\n",
    "    variable_id=variable_ids,\n",
    ")\n",
    "ds_dict = cat.to_dataset_dict(**kwargs)\n",
    "\n",
    "# # Trying to get the control runs going here, so do as little as possible?\n",
    "# variable_ids = [\"o2\"]  # \"mlotst\"\n",
    "\n",
    "# cat_control = col.search(\n",
    "#     source_id=models,\n",
    "#     grid_label=[\"gr\", \"gn\"],\n",
    "#     experiment_id=[\"piControl\"],\n",
    "#     table_id=[\"Omon\"],\n",
    "#     variable_id=variable_ids,\n",
    "# )\n",
    "# ds_dict_control = cat_control.to_dataset_dict(**kwargs)\n",
    "\n",
    "\n",
    "# make a separate metric dict to catch all possible metrics!\n",
    "cat_metrics = col.search(source_id=models, variable_id=metric_variable_ids)\n",
    "ds_metric_dict = cat_metrics.to_dataset_dict(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8300d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine in time (only needed for netcdf collection)\n",
    "ds_dict = concat_time(ds_dict)\n",
    "ds_metric_dict = concat_time(ds_metric_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3c9549",
   "metadata": {},
   "source": [
    "## brute force the GFDL age in the dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5607a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Brute Force add the GFDL age\n",
    "# # TODO: Make this nicer with the original netcdf files (not tonight though)\n",
    "# col_gfdl = cmip6_collection(zarr=True)\n",
    "# # BUG: There is something weird going on in the reading process here\n",
    "# # Just drop everything that is not GFDL\n",
    "# df = col_gfdl.df\n",
    "# df = df.iloc[ ['GFDL' in i for i in df['source_id']], :]\n",
    "# df = df.iloc[ ['agessc' in i for i in df['variable_id']], :]\n",
    "# col_gfdl.df = df\n",
    "# cat_gfdl = col_gfdl.search(\n",
    "#     source_id=[\n",
    "#         \"GFDL-CM4\",\n",
    "#         \"GFDL-ESM4\", \n",
    "#     ],\n",
    "#     variable_id=[\"agessc\"],\n",
    "#     experiment_id=[\"historical\", \"ssp585\"],\n",
    "# )\n",
    "\n",
    "# ddict_gfdl_age = cat_gfdl.to_dataset_dict(**kwargs)\n",
    "# ddict_gfdl_age = {k:ds for k, ds in ddict_gfdl_age.items()}\n",
    "# ds_dict.update(ddict_gfdl_age)\n",
    "\n",
    "# # rechunk the GFDL models in depth\n",
    "# def maybe_rechunk(ds):\n",
    "#     if ds.source_id in [\"GFDL-CM4\",\"GFDL-ESM4\"]:\n",
    "#         ds = ds.chunk({'lev':5})\n",
    "#     return ds\n",
    "# ds_dict = {k:maybe_rechunk(ds) for k,ds in ds_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d1bf79",
   "metadata": {},
   "source": [
    "## Cleanup datasets early\n",
    "\n",
    "I am currently: \n",
    "- dropping all variables except for the one specified in ds.variable_id\n",
    "- Checking if datasets have the expected length (otherwise drop)\n",
    "\n",
    "I am currently allowing longer ssp585 runs, but could cut them here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28479be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def _expected_length(ds):\n",
    "    if ds.experiment_id == \"historical\":\n",
    "        if ds.table_id == \"Omon\":\n",
    "            return 1980\n",
    "        else:\n",
    "            warnings.warn(\n",
    "                f\"unknown table_id [{ds.table_id}] for {cmip6_dataset_id(ds)}\"\n",
    "            )\n",
    "            return 1\n",
    "\n",
    "    elif \"ssp\" in ds.experiment_id:\n",
    "        if ds.table_id == \"Omon\":\n",
    "            return 1032\n",
    "        else:\n",
    "            warnings.warn(\n",
    "                f\"unknown table_id [{ds.table_id}] for {cmip6_dataset_id(ds)}\"\n",
    "            )\n",
    "            return 1\n",
    "\n",
    "    elif \"Control\" in ds.experiment_id:\n",
    "        if ds.table_id == \"Omon\":\n",
    "            return (\n",
    "                12 * 50\n",
    "            )  # just give a low number here so none of the controls are dropped\n",
    "        else:\n",
    "            warnings.warn(\n",
    "                f\"unknown table_id [{ds.table_id}] for {cmip6_dataset_id(ds)}\"\n",
    "            )\n",
    "            return 1\n",
    "    else:\n",
    "        warnings.warn(\n",
    "            f\"unknown experiment_id [{ds.experiment_id}] for {cmip6_dataset_id(ds)}\"\n",
    "        )\n",
    "        return 1\n",
    "\n",
    "\n",
    "def filter_ddict(ddict):\n",
    "    ddict_filtered = {}\n",
    "    for name, ds in ddict.items():\n",
    "        # drop everything but main variable\n",
    "        ds = ds.drop([v for v in ds.data_vars if v != ds.variable_id])\n",
    "\n",
    "        # filter out too short runs\n",
    "        if \"time\" not in ds.dims:\n",
    "            ddict_filtered[name] = ds\n",
    "        else:\n",
    "            if len(ds.time) < _expected_length(ds):\n",
    "                print(\"---------DROPPED--------\")\n",
    "                print(name)\n",
    "                print(_expected_length(ds))\n",
    "                print(len(ds.time))\n",
    "                print(\"---------DROPPED--------\")\n",
    "            else:\n",
    "                ddict_filtered[name] = ds\n",
    "    return ddict_filtered\n",
    "\n",
    "\n",
    "# apply to data and metrics\n",
    "ds_dict_filtered = filter_ddict(ds_dict)\n",
    "ds_metric_dict_filtered = filter_ddict(ds_metric_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5fa8faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='510' class='' max='510' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [510/510 00:33<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pathlib\n",
    "# new files (change in later and get rid of `load_trend_dict` (or refactor?) and `fix_trend_metadata`)\n",
    "# Load all trend files\n",
    "flist = list(pathlib.Path('../../data/external/cmip6_control_drifts/').absolute().glob('*.nc'))\n",
    "flist = [f for f in flist if any([v in str(f) for v in variable_ids])]\n",
    "trend_dict = {}\n",
    "for f in progress_bar(flist):\n",
    "    trend_dict[f.stem] = xr.open_mfdataset([f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48540365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MOHC.UKESM1-0-LL.historical.r12i1p1f2.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r5i1p1f1.Omon.gn.none.so\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r8i1p1f1.Omon.gn.none.so\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NCC.NorESM2-LM.historical.r1i1p1f1.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r3i1p1f1.Omon.gn.none.o2\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MOHC.UKESM1-0-LL.historical.r7i1p1f3.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r6i1p1f1.Omon.gn.none.thetao\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r9i1p1f1.Omon.gn.none.thetao\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r7i1p1f1.Omon.gn.none.thetao\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r3i1p1f1.Omon.gn.none.thetao\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r7i1p1f1.Omon.gn.none.so\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r5i1p1f1.Omon.gn.none.thetao\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NCC.NorESM2-MM.historical.r1i1p1f1.Omon.gn.none.so\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for ScenarioMIP.DWD.MPI-ESM1-2-HR.ssp585.r2i1p1f1.Omon.gn.none.o2\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NCC.NorESM2-MM.historical.r2i1p1f1.Omon.gn.none.so\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r2i1p1f1.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for ScenarioMIP.DWD.MPI-ESM1-2-HR.ssp585.r2i1p1f1.Omon.gn.none.thetao\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r3i1p1f1.Omon.gn.none.so\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r3i1p1f1.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NIMS-KMA.UKESM1-0-LL.historical.r13i1p1f2.Omon.gn.none.so\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r2i1p1f1.Omon.gn.none.so\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r10i1p1f1.Omon.gn.none.o2\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MOHC.UKESM1-0-LL.historical.r1i1p1f2.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NCC.NorESM2-MM.historical.r2i1p1f1.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NCC.NorESM2-LM.historical.r3i1p1f1.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for ScenarioMIP.DWD.MPI-ESM1-2-HR.ssp585.r2i1p1f1.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NCC.NorESM2-LM.historical.r2i1p1f1.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NCC.NorESM2-MM.historical.r3i1p1f1.Omon.gn.none.thetao\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r4i1p1f1.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r6i1p1f1.Omon.gn.none.o2\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r10i1p1f1.Omon.gn.none.so\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MRI.MRI-ESM2-0.historical.r1i1000p1f1.Omon.gr.none.so\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r9i1p1f1.Omon.gn.none.o2\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r9i1p1f1.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r4i1p1f1.Omon.gn.none.thetao\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for ScenarioMIP.NCC.NorESM2-MM.ssp585.r1i1p1f1.Omon.gn.none.thetao\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NCC.NorESM2-MM.historical.r2i1p1f1.Omon.gr.none.thetao\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for ScenarioMIP.NCC.NorESM2-MM.ssp585.r1i1p1f1.Omon.gn.none.so\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r10i1p1f1.Omon.gn.none.thetao\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r8i1p1f1.Omon.gn.none.thetao\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r8i1p1f1.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r7i1p1f1.Omon.gn.none.o2\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for ScenarioMIP.NCC.NorESM2-MM.ssp585.r1i1p1f1.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r7i1p1f1.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NCC.NorESM2-MM.historical.r2i1p1f1.Omon.gn.none.thetao\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NCC.NorESM2-MM.historical.r1i1p1f1.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MOHC.UKESM1-0-LL.historical.r6i1p1f3.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NCC.NorESM2-LM.historical.r2i1p1f1.Omon.gn.none.so\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for ScenarioMIP.DWD.MPI-ESM1-2-HR.ssp585.r2i1p1f1.Omon.gn.none.so\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MOHC.UKESM1-0-LL.historical.r3i1p1f2.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r6i1p1f1.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NCC.NorESM2-MM.historical.r3i1p1f1.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r2i1p1f1.Omon.gn.none.o2\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MOHC.UKESM1-0-LL.historical.r2i1p1f2.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r4i1p1f1.Omon.gn.none.o2\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for ScenarioMIP.NCC.NorESM2-LM.ssp585.r1i1p1f1.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NCC.NorESM2-LM.historical.r2i1p1f1.Omon.gn.none.thetao\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NCC.NorESM2-LM.historical.r3i1p1f1.Omon.gn.none.thetao\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NCC.NorESM2-MM.historical.r3i1p1f1.Omon.gr.none.so\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r4i1p1f1.Omon.gn.none.so\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MOHC.UKESM1-0-LL.historical.r16i1p1f2.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r6i1p1f1.Omon.gn.none.so\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for ScenarioMIP.NCC.NorESM2-LM.ssp585.r1i1p1f1.Omon.gn.none.thetao\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NIMS-KMA.UKESM1-0-LL.historical.r13i1p1f2.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r10i1p1f1.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r5i1p1f1.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NCC.NorESM2-MM.historical.r3i1p1f1.Omon.gn.none.so\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r9i1p1f1.Omon.gn.none.so\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NCC.NorESM2-MM.historical.r3i1p1f1.Omon.gr.none.o2\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NCC.NorESM2-LM.historical.r1i1p1f1.Omon.gn.none.so\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NCC.NorESM2-MM.historical.r1i1p1f1.Omon.gn.none.thetao\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NCC.NorESM2-LM.historical.r3i1p1f1.Omon.gn.none.so\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NCC.NorESM2-MM.historical.r3i1p1f1.Omon.gr.none.thetao\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r2i1p1f1.Omon.gn.none.thetao\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for ScenarioMIP.NCC.NorESM2-LM.ssp585.r1i1p1f1.Omon.gn.none.so\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MOHC.UKESM1-0-LL.historical.r19i1p1f2.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NCC.NorESM2-LM.historical.r1i1p1f1.Omon.gn.none.thetao\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r5i1p1f1.Omon.gn.none.o2\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MPI-M.MPI-ESM1-2-HR.historical.r8i1p1f1.Omon.gn.none.o2\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MOHC.UKESM1-0-LL.historical.r9i1p1f2.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MOHC.UKESM1-0-LL.historical.r5i1p1f3.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MRI.MRI-ESM2-0.historical.r1i1000p1f1.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MRI.MRI-ESM2-0.historical.r1i1000p1f1.Omon.gr.none.thetao\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NCC.NorESM2-MM.historical.r3i1p1f1.Omon.gr.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MOHC.UKESM1-0-LL.historical.r8i1p1f2.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for ScenarioMIP.MOHC.UKESM1-0-LL.ssp585.r1i1p1f2.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for ScenarioMIP.MOHC.UKESM1-0-LL.ssp585.r8i1p1f2.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for ScenarioMIP.MOHC.UKESM1-0-LL.ssp585.r4i1p1f2.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MOHC.UKESM1-0-LL.historical.r18i1p1f2.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MOHC.UKESM1-0-LL.historical.r4i1p1f2.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MOHC.UKESM1-0-LL.historical.r19i1p1f2.Omon.gn.none.thetao\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MOHC.UKESM1-0-LL.historical.r19i1p1f2.Omon.gn.none.so\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MOHC.UKESM1-0-LL.historical.r11i1p1f2.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MRI.MRI-ESM2-0.historical.r1i1000p1f1.Omon.gn.none.thetao\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MRI.MRI-ESM2-0.historical.r1i1000p1f1.Omon.gn.none.so\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for ScenarioMIP.MOHC.UKESM1-0-LL.ssp585.r3i1p1f2.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MOHC.UKESM1-0-LL.historical.r19i1p1f2.Omon.gn.none.o2\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MOHC.UKESM1-0-LL.historical.r10i1p1f2.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for ScenarioMIP.MOHC.UKESM1-0-LL.ssp585.r2i1p1f2.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MOHC.UKESM1-0-LL.historical.r17i1p1f2.Omon.gn.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NIMS-KMA.UKESM1-0-LL.historical.r13i1p1f2.Omon.gn.none.o2\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.MRI.MRI-ESM2-0.historical.r1i1000p1f1.Omon.gr.none.agessc\n",
      "  warnings.warn(nomatch_msg)\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:60: UserWarning: Could not find a matching dataset for CMIP.NIMS-KMA.UKESM1-0-LL.historical.r13i1p1f2.Omon.gn.none.thetao\n",
      "  warnings.warn(nomatch_msg)\n"
     ]
    }
   ],
   "source": [
    "# these ones are messed up...need a better way to deal with that in the previous step\n",
    "# see https://github.com/jbusecke/cmip6_preprocessing/issues/175\n",
    "incomplete_keys = ['CMIP.IPSL.IPSL-CM6A-LR.historical.r3i1p1f1.Omon.gn.none.area_o2']\n",
    "trend_dict = {k:ds for k,ds in trend_dict.items() if k not in incomplete_keys}\n",
    "# i think this should be taken care of in the filtering step above...TODO check at a later point\n",
    "\n",
    "ddict_tracers_detrended = match_and_remove_trend(\n",
    "    ds_dict_filtered,\n",
    "    trend_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909c1149",
   "metadata": {},
   "source": [
    "## Match metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25092a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these cause trouble\n",
    "problem_metrics = [\n",
    "    'ACCESS-ESM1-5.gn.ssp585.Omon.r3i1p1f1.thkcello', # metric too short\n",
    "    'ACCESS-ESM1-5.gn.ssp585.Omon.r2i1p1f1.thkcello', # metric too short\n",
    "    'ACCESS-ESM1-5.gn.ssp585.Omon.r1i1p1f1.thkcello', # metric too long (I guess I could fix that with a join='inner', but probably not worth it now\n",
    "    'ACCESS-ESM1-5.gn.ssp585.Omon.r9i1p1f1.thkcello', # metric too short\n",
    "    'ACCESS-ESM1-5.gn.ssp585.Omon.r6i1p1f1.thkcello', # metric too long (I guess I could fix that with a join='inner', but probably not worth it now\n",
    "    'ACCESS-ESM1-5.gn.ssp585.Omon.r4i1p1f1.thkcello', # metric too long (I guess I could fix that with a join='inner', but probably not worth it now\n",
    "    'ACCESS-ESM1-5.gn.ssp585.Omon.r8i1p1f1.thkcello', # metric too long (I guess I could fix that with a join='inner', but probably not worth it now\n",
    "    'ACCESS-ESM1-5.gn.ssp585.Omon.r10i1p1f1.thkcello', # metric too long (I guess I could fix that with a join='inner', but probably not worth it now\n",
    "    'ACCESS-ESM1-5.gn.ssp585.Omon.r5i1p1f1.thkcello', # metric too long (I guess I could fix that with a join='inner', but probably not worth it now\n",
    "]\n",
    "for key in problem_metrics:\n",
    "    if key in ds_metric_dict_filtered.keys():\n",
    "        del ds_metric_dict_filtered[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "310613a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:615: UserWarning: No matching metrics found for areacello\n",
      "  warnings.warn(f\"No matching metrics found for {mv}\")\n",
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:615: UserWarning: No matching metrics found for thkcello\n",
      "  warnings.warn(f\"No matching metrics found for {mv}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 225 datasets.\n",
      "Exact matches:{'areacello': 0, 'thkcello': 148}\n",
      "Other matches:{'areacello': 174, 'thkcello': 27}\n",
      "No match found:{'areacello': 51, 'thkcello': 50}\n"
     ]
    }
   ],
   "source": [
    "# this one causes problems because the time is not as long as the full data...apparently they stopped writing the thickness\n",
    "# ddict_tracers_detrended_filtered = {\n",
    "#     k: ds.squeeze()\n",
    "#     for k, ds in ddict_tracers_detrended.items()\n",
    "#     if not (\"ACCESS-ESM1-5\" in k and \"r3i1p1f1\" in k)\n",
    "# }\n",
    "\n",
    "ddict_matched = match_metrics(\n",
    "    ddict_tracers_detrended,\n",
    "    ds_metric_dict_filtered,\n",
    "    [\"areacello\", \"thkcello\"],\n",
    "    print_statistics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c850b678",
   "metadata": {},
   "source": [
    "## Interpolate Grids and merge variables\n",
    "\n",
    "- handle the Norwegian Models inside `interpolate_grid_label` (TODO: Check if this works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63c400f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolate grids\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "with dask.config.set(**{'array.slicing.split_large_chunks': True}): # only necessary for ACCESS, they are all different lengths?\n",
    "\n",
    "    print(\"interpolate grids\\n\")\n",
    "    ddict_matched_regrid = interpolate_grid_label(\n",
    "        ddict_matched, merge_kwargs={\"compat\": \"override\"}\n",
    "    )  # This should be a default soon\n",
    "\n",
    "# #patch the norwegian model in manually\n",
    "# ddict_patch = merge_variables(ddict_matched)\n",
    "# for name, ds in ddict_patch.items():\n",
    "#     if 'Nor' in name and 'gr' in name:\n",
    "#         patch_name = name.replace('.gr','')\n",
    "#         ddict_matched_regrid[patch_name] = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11e20b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MPI-ESM1-2-HR.historical.Omon.r1i1p1f1',\n",
       "       'MPI-ESM1-2-HR.ssp585.Omon.r1i1p1f1',\n",
       "       'MPI-ESM1-2-LR.historical.Omon.r10i1p1f1',\n",
       "       'MPI-ESM1-2-LR.historical.Omon.r1i1p1f1',\n",
       "       'MPI-ESM1-2-LR.historical.Omon.r2i1p1f1',\n",
       "       'MPI-ESM1-2-LR.historical.Omon.r3i1p1f1',\n",
       "       'MPI-ESM1-2-LR.historical.Omon.r4i1p1f1',\n",
       "       'MPI-ESM1-2-LR.historical.Omon.r5i1p1f1',\n",
       "       'MPI-ESM1-2-LR.historical.Omon.r6i1p1f1',\n",
       "       'MPI-ESM1-2-LR.historical.Omon.r7i1p1f1',\n",
       "       'MPI-ESM1-2-LR.historical.Omon.r8i1p1f1',\n",
       "       'MPI-ESM1-2-LR.historical.Omon.r9i1p1f1',\n",
       "       'MPI-ESM1-2-LR.ssp585.Omon.r10i1p1f1',\n",
       "       'MPI-ESM1-2-LR.ssp585.Omon.r1i1p1f1',\n",
       "       'MPI-ESM1-2-LR.ssp585.Omon.r2i1p1f1',\n",
       "       'MPI-ESM1-2-LR.ssp585.Omon.r3i1p1f1',\n",
       "       'MPI-ESM1-2-LR.ssp585.Omon.r4i1p1f1',\n",
       "       'MPI-ESM1-2-LR.ssp585.Omon.r5i1p1f1',\n",
       "       'MPI-ESM1-2-LR.ssp585.Omon.r6i1p1f1',\n",
       "       'MPI-ESM1-2-LR.ssp585.Omon.r7i1p1f1',\n",
       "       'MPI-ESM1-2-LR.ssp585.Omon.r8i1p1f1',\n",
       "       'MPI-ESM1-2-LR.ssp585.Omon.r9i1p1f1',\n",
       "       'MRI-ESM2-0.historical.Omon.r1i1p1f1',\n",
       "       'MRI-ESM2-0.historical.Omon.r1i2p1f1',\n",
       "       'MRI-ESM2-0.historical.Omon.r2i1p1f1',\n",
       "       'MRI-ESM2-0.historical.Omon.r3i1p1f1',\n",
       "       'MRI-ESM2-0.historical.Omon.r4i1p1f1',\n",
       "       'MRI-ESM2-0.historical.Omon.r5i1p1f1',\n",
       "       'MRI-ESM2-0.ssp585.Omon.r1i1p1f1',\n",
       "       'MRI-ESM2-0.ssp585.Omon.r1i2p1f1',\n",
       "       'NorESM2-LM.historical.Omon.r1i1p1f1',\n",
       "       'NorESM2-LM.historical.Omon.r2i1p1f1',\n",
       "       'NorESM2-LM.historical.Omon.r3i1p1f1',\n",
       "       'NorESM2-LM.ssp585.Omon.r1i1p1f1',\n",
       "       'NorESM2-MM.historical.Omon.r1i1p1f1',\n",
       "       'NorESM2-MM.historical.Omon.r2i1p1f1',\n",
       "       'NorESM2-MM.ssp585.Omon.r1i1p1f1',\n",
       "       'UKESM1-0-LL.historical.Omon.r10i1p1f2',\n",
       "       'UKESM1-0-LL.historical.Omon.r11i1p1f2',\n",
       "       'UKESM1-0-LL.historical.Omon.r12i1p1f2',\n",
       "       'UKESM1-0-LL.historical.Omon.r16i1p1f2',\n",
       "       'UKESM1-0-LL.historical.Omon.r17i1p1f2',\n",
       "       'UKESM1-0-LL.historical.Omon.r18i1p1f2',\n",
       "       'UKESM1-0-LL.historical.Omon.r1i1p1f2',\n",
       "       'UKESM1-0-LL.historical.Omon.r2i1p1f2',\n",
       "       'UKESM1-0-LL.historical.Omon.r3i1p1f2',\n",
       "       'UKESM1-0-LL.historical.Omon.r4i1p1f2',\n",
       "       'UKESM1-0-LL.historical.Omon.r5i1p1f3',\n",
       "       'UKESM1-0-LL.historical.Omon.r6i1p1f3',\n",
       "       'UKESM1-0-LL.historical.Omon.r7i1p1f3',\n",
       "       'UKESM1-0-LL.historical.Omon.r8i1p1f2',\n",
       "       'UKESM1-0-LL.historical.Omon.r9i1p1f2',\n",
       "       'UKESM1-0-LL.ssp585.Omon.r1i1p1f2',\n",
       "       'UKESM1-0-LL.ssp585.Omon.r2i1p1f2',\n",
       "       'UKESM1-0-LL.ssp585.Omon.r3i1p1f2',\n",
       "       'UKESM1-0-LL.ssp585.Omon.r4i1p1f2',\n",
       "       'UKESM1-0-LL.ssp585.Omon.r8i1p1f2'], dtype='<U39')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(list(ddict_matched_regrid.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68540f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # manually remove GFDL (delete again, only necessary because of the brute force gFDL age)\n",
    "# ddict_matched_regrid = {k:ds for k,ds in ddict_matched_regrid.items() if 'GFDL' not in k}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47ed527",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Concatenate experiments and pick only 'full (both hist and ssp)' runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3be924f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbusecke/code/miniconda/envs/cmip6_omz/lib/python3.9/site-packages/cmip6_preprocessing/postprocessing.py:113: UserWarning: Match attributes ['variable_id'] not found in any of the datasets.         This can happen when several combination functions are used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# somehow xarray cannot deal with comparing list/int attrs (Occurs in CM4)\n",
    "\n",
    "# def _clean(obj):\n",
    "#     for a, attr in obj.attrs.items():\n",
    "#         if isinstance(attr, np.integer):\n",
    "#             obj.attrs[a] = [int(attr)]\n",
    "# #             print('converted to int', a, attr)\n",
    "#         elif isinstance(attr, np.floating):\n",
    "#             obj.attrs[a] = [float(attr)]\n",
    "# #         elif isinstance(attr, list):\n",
    "# #             print([type(i) for i in attr])\n",
    "#     return obj\n",
    "#             # I should raise that, but lets fix it quickly here\n",
    "\n",
    "# def clean_attrs(ds):\n",
    "#     ds = _clean(ds)\n",
    "#     for va in ds.variables:\n",
    "#         ds[va] = _clean(ds[va])    \n",
    "#     return ds\n",
    "\n",
    "ddict_ex_combined = concat_experiments(\n",
    "    ddict_matched_regrid,\n",
    "    concat_kwargs={\n",
    "        'combine_attrs': 'drop_conflicts',\n",
    "        'compat': 'override',\n",
    "        'coords': 'minimal'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7ed021",
   "metadata": {},
   "source": [
    "Still need to deal with the access stuff here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fb8876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only pick full runs (historical and ssp585)\n",
    "ddict_ex_combined_full = {k:ds for k,ds in ddict_ex_combined.items() if len(ds.time)>3000}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7358533e",
   "metadata": {},
   "source": [
    "## Check for problems and fix missing area/thickness manually\n",
    "\n",
    "This should be wrapped and brought upstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0cd614b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'missing_variables': [('MRI-ESM2-0.gn.Omon.r1i1p1f1', ['o2'])],\n",
       " 'missing_area': [],\n",
       " 'missing_thickness': [],\n",
       " 'reconstructed_area': ['NorESM2-MM.gr.Omon.r1i1p1f1',\n",
       "  'NorESM2-LM.gr.Omon.r1i1p1f1'],\n",
       " 'reconstructed_thickness': ['MRI-ESM2-0.gn.Omon.r1i1p1f1',\n",
       "  'MRI-ESM2-0.gn.Omon.r1i2p1f1']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cmip6_preprocessing.grids import combine_staggered_grid\n",
    "problems = {'missing_variables':[], 'missing_area':[], 'missing_thickness':[], 'reconstructed_area':[], 'reconstructed_thickness':[]}\n",
    "ddict_filtered = {}\n",
    "for name, ds in ddict_ex_combined_full.items():\n",
    "    flag = False\n",
    "    # Check that all necessary variables are given\n",
    "    missing_variables = [va for va in [\"thetao\", \"so\", \"o2\"] if va not in ds.variables]\n",
    "    if len(missing_variables)>0:\n",
    "        flag = True\n",
    "        problems['missing_variables'].append((name, missing_variables))\n",
    "        \n",
    "    # Check for area\n",
    "    if not 'areacello' in ds.coords:\n",
    "        if ds.attrs['grid_label'] == 'gr': # only reconstruct for regular grids\n",
    "            grid, ds = combine_staggered_grid(ds, recalculate_metrics=True)\n",
    "            # I am dropping dz_t here so it can be uniformly reconstructed\n",
    "            ds = ds.drop('dz_t')\n",
    "            ds = ds.assign_coords(areacello = (ds.dx_t * ds.dy_t).reset_coords(drop=True))\n",
    "            problems['reconstructed_area'].append(name)\n",
    "            assert 'areacello' in ds.coords\n",
    "        else:\n",
    "            flag = True\n",
    "            problems['missing_area'].append(name)\n",
    "    \n",
    "    # Check for thickness (and rename) TODO: We should probably not rename and just refactor to use `thkcello`\n",
    "    if \"thkcello\" in ds.coords:\n",
    "        ds = ds.rename({'thkcello': 'dz_t'})\n",
    "    else:\n",
    "        # try to reconstruct the thickness from static info\n",
    "        try:\n",
    "#             lev_vertices = cf_xarray.bounds_to_vertices(ds.lev_bounds, 'bnds').load()\n",
    "#             dz_t = lev_vertices.diff('lev_vertices')\n",
    "#             ds = ds.assign_coords(dz_t=('lev', dz_t.data))\n",
    "            ds = construct_static_dz(ds).rename({'thkcello': 'dz_t'})\n",
    "            problems['reconstructed_thickness'].append(name)\n",
    "        except Exception as e:\n",
    "            print(f'{name} thickness reconstruction failed with {e}')\n",
    "            print(ds)\n",
    "            problems['missing_thickness'].append(name)\n",
    "            flag=True\n",
    "            \n",
    "    if not flag:\n",
    "        ddict_filtered[name] = ds\n",
    "problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c58c1e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MPI-ESM1-2-HR.gn.Omon.r1i1p1f1',\n",
       " 'MPI-ESM1-2-LR.gn.Omon.r10i1p1f1',\n",
       " 'MPI-ESM1-2-LR.gn.Omon.r1i1p1f1',\n",
       " 'MPI-ESM1-2-LR.gn.Omon.r2i1p1f1',\n",
       " 'MPI-ESM1-2-LR.gn.Omon.r3i1p1f1',\n",
       " 'MPI-ESM1-2-LR.gn.Omon.r4i1p1f1',\n",
       " 'MPI-ESM1-2-LR.gn.Omon.r5i1p1f1',\n",
       " 'MPI-ESM1-2-LR.gn.Omon.r6i1p1f1',\n",
       " 'MPI-ESM1-2-LR.gn.Omon.r7i1p1f1',\n",
       " 'MPI-ESM1-2-LR.gn.Omon.r8i1p1f1',\n",
       " 'MPI-ESM1-2-LR.gn.Omon.r9i1p1f1',\n",
       " 'MRI-ESM2-0.gn.Omon.r1i2p1f1',\n",
       " 'NorESM2-LM.gr.Omon.r1i1p1f1',\n",
       " 'NorESM2-MM.gr.Omon.r1i1p1f1',\n",
       " 'UKESM1-0-LL.gn.Omon.r1i1p1f2',\n",
       " 'UKESM1-0-LL.gn.Omon.r2i1p1f2',\n",
       " 'UKESM1-0-LL.gn.Omon.r3i1p1f2',\n",
       " 'UKESM1-0-LL.gn.Omon.r4i1p1f2',\n",
       " 'UKESM1-0-LL.gn.Omon.r8i1p1f2']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ddict_final = pick_first_member(ddict_filtered)#\n",
    "\n",
    "# Final version: Put out all full memmbers\n",
    "ddict_final = ddict_filtered\n",
    "\n",
    "list(np.sort(list(ddict_final.keys())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c565a6",
   "metadata": {},
   "source": [
    "## Prep Basin mask\n",
    "- Needs a separated Indian Ocean (Sam uses: 78E)\n",
    "- Refactor with the new masking using cf-xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c910c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ocean basin data\n",
    "import regionmask\n",
    "basins = regionmask.defined_regions.natural_earth.ocean_basins_50\n",
    "from cmip6_preprocessing.regionmask import merged_mask\n",
    "from cmip6_preprocessing.regionmask import _default_merge_dict\n",
    "mask_labels_raw = {label:mi for mi, label in enumerate(_default_merge_dict().keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fe6b7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_split_indian_labels(mask_labels):\n",
    "    # modify the mask labels\n",
    "    modified_mask_labels = {}\n",
    "    for label, i in mask_labels.items():\n",
    "        if i>5:\n",
    "            i += 1\n",
    "\n",
    "        if i!=5:\n",
    "            modified_mask_labels[label] = i\n",
    "        else:\n",
    "            modified_mask_labels['Indian_AS'] = 5\n",
    "            modified_mask_labels['Indian_BOB'] = 6\n",
    "    return modified_mask_labels\n",
    "\n",
    "def mask_split_indian(ds, mask, mask_labels, plot=True):\n",
    "    # first move all labels (including Indian) one up\n",
    "    mask_modified = mask.where(mask<5, mask+1)\n",
    "\n",
    "    # Now move the Arabian sea one down again\n",
    "    mask_modified = mask_modified.where(~np.logical_and(mask_modified==6, ds.lon<78), 5)\n",
    "    \n",
    "    mask_labels_modified = mask_split_indian_labels(mask_labels)\n",
    "    \n",
    "    if plot:\n",
    "        fig, axarr = plt.subplots(ncols=4, nrows=4, figsize=[15,10])\n",
    "        for ax,(label,i) in zip(axarr.flat, mask_labels_modified.items()):\n",
    "            mask_modified.where(mask_modified==i).plot(ax=ax)\n",
    "            ax.set_title(label)\n",
    "        fig.subplots_adjust(hspace=0.7, wspace=0.7)\n",
    "        plt.show()\n",
    "    return mask_modified, mask_labels_modified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5143faa",
   "metadata": {},
   "source": [
    "## Lets check how to split the Indian Ocean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e49cc62",
   "metadata": {},
   "source": [
    "## This needs to go within the loop later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b6f5feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_nan(ds, sub_slices={\"time\": slice(12, 24)}):\n",
    "    \"\"\"adjusts all data_variables to have nans in the same spots\"\"\"\n",
    "    # TODO: The GFDL age has all nan slices at the beginning and end due to interpolation\n",
    "    # extract subsets\n",
    "    datasets = [ds[va] for va in ds.data_vars]\n",
    "    datasets = [\n",
    "        da.isel(**{di: v for di, v in sub_slices.items() if di in da.dims})\n",
    "        for da in datasets\n",
    "    ]\n",
    "    datasets = [np.isnan(da) for da in datasets]\n",
    "    mask = (\n",
    "        sum(datasets)\n",
    "        .astype(bool)\n",
    "        .any([di for di in sub_slices.keys() if di in ds.dims])\n",
    "    )\n",
    "    return ds.where(~mask)\n",
    "\n",
    "\n",
    "def full_wrapper(ds):\n",
    "\n",
    "    ## Define bins\n",
    "\n",
    "    o2_bins = np.hstack(\n",
    "        [-100, np.arange(0, 25, 5), np.arange(30, 180, 10), 1e5]\n",
    "    )  # in mymol/kg\n",
    "    o2_bins_converted = bins_converted = (\n",
    "        o2_bins / convert_mol_m3_mymol_kg(xr.DataArray([1])).data\n",
    "    )\n",
    "    # define mask bins\n",
    "    #\n",
    "    mask_bins = np.arange(-0.5, 7.0, 1)\n",
    "    # this does not include all basins\n",
    "    # but it will save some space and we (for now) dont care about OMZs\n",
    "    # in the Caspian Sea\n",
    "    mask_bin_labels = [\n",
    "        label\n",
    "        for label, i in mask_split_indian_labels(mask_labels_raw).items()\n",
    "        if i < mask_bins.max()\n",
    "    ]\n",
    "    assert len(mask_bin_labels) == len(mask_bins) - 1\n",
    "\n",
    "    lat_bins = np.arange(-60, 61, 10)\n",
    "\n",
    "    ##\n",
    "\n",
    "    ds[\"vol\"] = ds.dz_t * ds.areacello\n",
    "\n",
    "    ds = unify_nan(ds)\n",
    "\n",
    "    # Masking\n",
    "    mask = merged_mask(basins, ds)\n",
    "    mask, _ = mask_split_indian(ds, mask, mask_labels_raw, plot=False)\n",
    "    mask.name = \"basin_mask\"\n",
    "\n",
    "    \n",
    "    vol = ds[\"vol\"]\n",
    "    \n",
    "    \n",
    "    count = histogram(\n",
    "        ds.o2,\n",
    "        ds.lat,\n",
    "        mask,\n",
    "        bins=[o2_bins_converted, lat_bins, mask_bins],\n",
    "        dim=[\"x\", \"y\"],\n",
    "    )\n",
    "    volume = histogram(\n",
    "        ds.o2,\n",
    "        ds.lat,\n",
    "        mask,\n",
    "        bins=[o2_bins_converted, lat_bins, mask_bins],\n",
    "        weights=vol,\n",
    "        dim=[\"x\", \"y\"],\n",
    "    )\n",
    "    # drop volume or it will get combined as tracer.\n",
    "    ds = ds.drop([\"vol\"])\n",
    "    tracers = {}\n",
    "    for tr in ds.data_vars:\n",
    "        tracers[tr] = histogram(\n",
    "            ds.o2,\n",
    "            ds.lat,\n",
    "            mask,\n",
    "            bins=[o2_bins_converted, lat_bins, mask_bins],\n",
    "            weights=ds[tr] * vol,\n",
    "            dim=[\"x\", \"y\"],\n",
    "        )\n",
    "    ds_hist = xr.Dataset(dict(bin_count=count, volume=volume, **tracers))\n",
    "    ds_hist.attrs = {\n",
    "        k: v for k, v in ds.attrs.items() if k not in [\"intake_esm_varname\"]\n",
    "    }\n",
    "\n",
    "    # Add more coordinates etc to the output\n",
    "    ds_hist = ds_hist.assign_coords(o2_bin=convert_mol_m3_mymol_kg(ds_hist.o2_bin).data)\n",
    "    ds_hist[\"o2_bin\"].attrs[\"units\"] = \"$\\mu mol$/kg\"\n",
    "    ds_hist = ds_hist.assign_coords(lev_bounds=ds.lev_bounds)\n",
    "    ds_hist = ds_hist.assign_coords(basin_mask_bin=mask_bin_labels)\n",
    "    ds_hist = ds_hist.assign_coords(\n",
    "        o2_bin_bounds=cf_xarray.vertices_to_bounds(\n",
    "            xr.DataArray(o2_bins, dims=\"o2_bin\"),\n",
    "            [\n",
    "                \"bnds\",\n",
    "                \"o2_bin\",\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    "    ds_hist = ds_hist.assign_coords(\n",
    "        lat_bounds=cf_xarray.vertices_to_bounds(\n",
    "            xr.DataArray(lat_bins, dims=\"lat_bin\"),\n",
    "            [\n",
    "                \"bnds\",\n",
    "                \"lat_bin\",\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    "    return ds_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14519fd1",
   "metadata": {},
   "source": [
    "## Process the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46243b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR.gn.Omon.r1i1p1f1\n",
      "/projects/GEOCLIM/LRGROUP/jbusecke/projects_data/cmip6_depth_histogram_v2.3/none.none.MPI-ESM1-2-HR.none.r1i1p1f1.Omon.gn.none.none.zarr\n",
      "Exists already\n",
      "NorESM2-MM.gr.Omon.r1i1p1f1\n",
      "/projects/GEOCLIM/LRGROUP/jbusecke/projects_data/cmip6_depth_histogram_v2.3/none.NCC.NorESM2-MM.none.r1i1p1f1.Omon.gr.none.none.zarr\n",
      "Exists already\n",
      "MPI-ESM1-2-LR.gn.Omon.r4i1p1f1\n",
      "/projects/GEOCLIM/LRGROUP/jbusecke/projects_data/cmip6_depth_histogram_v2.3/none.MPI-M.MPI-ESM1-2-LR.none.r4i1p1f1.Omon.gn.none.none.zarr\n",
      "Exists already\n",
      "MPI-ESM1-2-LR.gn.Omon.r1i1p1f1\n",
      "/projects/GEOCLIM/LRGROUP/jbusecke/projects_data/cmip6_depth_histogram_v2.3/none.MPI-M.MPI-ESM1-2-LR.none.r1i1p1f1.Omon.gn.none.none.zarr\n",
      "Exists already\n",
      "NorESM2-LM.gr.Omon.r1i1p1f1\n",
      "/projects/GEOCLIM/LRGROUP/jbusecke/projects_data/cmip6_depth_histogram_v2.3/none.NCC.NorESM2-LM.none.r1i1p1f1.Omon.gr.none.none.zarr\n",
      "Exists already\n",
      "MPI-ESM1-2-LR.gn.Omon.r2i1p1f1\n",
      "/projects/GEOCLIM/LRGROUP/jbusecke/projects_data/cmip6_depth_histogram_v2.3/none.MPI-M.MPI-ESM1-2-LR.none.r2i1p1f1.Omon.gn.none.none.zarr\n",
      "Exists already\n",
      "MPI-ESM1-2-LR.gn.Omon.r6i1p1f1\n",
      "/projects/GEOCLIM/LRGROUP/jbusecke/projects_data/cmip6_depth_histogram_v2.3/none.MPI-M.MPI-ESM1-2-LR.none.r6i1p1f1.Omon.gn.none.none.zarr\n",
      "Exists already\n",
      "MPI-ESM1-2-LR.gn.Omon.r8i1p1f1\n",
      "/projects/GEOCLIM/LRGROUP/jbusecke/projects_data/cmip6_depth_histogram_v2.3/none.MPI-M.MPI-ESM1-2-LR.none.r8i1p1f1.Omon.gn.none.none.zarr\n",
      "Exists already\n",
      "MPI-ESM1-2-LR.gn.Omon.r9i1p1f1\n",
      "/projects/GEOCLIM/LRGROUP/jbusecke/projects_data/cmip6_depth_histogram_v2.3/none.MPI-M.MPI-ESM1-2-LR.none.r9i1p1f1.Omon.gn.none.none.zarr\n",
      "Exists already\n",
      "MPI-ESM1-2-LR.gn.Omon.r5i1p1f1\n",
      "/projects/GEOCLIM/LRGROUP/jbusecke/projects_data/cmip6_depth_histogram_v2.3/none.MPI-M.MPI-ESM1-2-LR.none.r5i1p1f1.Omon.gn.none.none.zarr\n",
      "Exists already\n",
      "MRI-ESM2-0.gn.Omon.r1i2p1f1\n",
      "/projects/GEOCLIM/LRGROUP/jbusecke/projects_data/cmip6_depth_histogram_v2.3/none.MRI.MRI-ESM2-0.none.r1i2p1f1.Omon.gn.none.none.zarr\n",
      "Exists already\n",
      "MPI-ESM1-2-LR.gn.Omon.r3i1p1f1\n",
      "/projects/GEOCLIM/LRGROUP/jbusecke/projects_data/cmip6_depth_histogram_v2.3/none.MPI-M.MPI-ESM1-2-LR.none.r3i1p1f1.Omon.gn.none.none.zarr\n",
      "Exists already\n",
      "MPI-ESM1-2-LR.gn.Omon.r10i1p1f1\n",
      "/projects/GEOCLIM/LRGROUP/jbusecke/projects_data/cmip6_depth_histogram_v2.3/none.MPI-M.MPI-ESM1-2-LR.none.r10i1p1f1.Omon.gn.none.none.zarr\n",
      "Exists already\n",
      "UKESM1-0-LL.gn.Omon.r1i1p1f2\n",
      "/projects/GEOCLIM/LRGROUP/jbusecke/projects_data/cmip6_depth_histogram_v2.3/none.MOHC.UKESM1-0-LL.none.r1i1p1f2.Omon.gn.none.none.zarr\n",
      "Exists already\n",
      "UKESM1-0-LL.gn.Omon.r3i1p1f2\n",
      "/projects/GEOCLIM/LRGROUP/jbusecke/projects_data/cmip6_depth_histogram_v2.3/none.MOHC.UKESM1-0-LL.none.r3i1p1f2.Omon.gn.none.none.zarr\n",
      "Exists already\n",
      "UKESM1-0-LL.gn.Omon.r8i1p1f2\n",
      "/projects/GEOCLIM/LRGROUP/jbusecke/projects_data/cmip6_depth_histogram_v2.3/none.MOHC.UKESM1-0-LL.none.r8i1p1f2.Omon.gn.none.none.zarr\n",
      "Exists already\n",
      "UKESM1-0-LL.gn.Omon.r4i1p1f2\n",
      "/projects/GEOCLIM/LRGROUP/jbusecke/projects_data/cmip6_depth_histogram_v2.3/none.MOHC.UKESM1-0-LL.none.r4i1p1f2.Omon.gn.none.none.zarr\n",
      "Exists already\n",
      "UKESM1-0-LL.gn.Omon.r2i1p1f2\n",
      "/projects/GEOCLIM/LRGROUP/jbusecke/projects_data/cmip6_depth_histogram_v2.3/none.MOHC.UKESM1-0-LL.none.r2i1p1f2.Omon.gn.none.none.zarr\n",
      "Exists already\n",
      "MPI-ESM1-2-LR.gn.Omon.r7i1p1f1\n",
      "/projects/GEOCLIM/LRGROUP/jbusecke/projects_data/cmip6_depth_histogram_v2.3/none.MPI-M.MPI-ESM1-2-LR.none.r7i1p1f1.Omon.gn.none.none.zarr\n",
      "Exists already\n"
     ]
    }
   ],
   "source": [
    "overwrite = False\n",
    "output_checks = False\n",
    "\n",
    "# TODO, rerun these all for v3 (probably want to forego the experiment concat)\n",
    "for name, ds in ddict_final.items():\n",
    "    print(name)\n",
    "    ds_hist = full_wrapper(ds)\n",
    "    # output checks\n",
    "    if output_checks:\n",
    "        for va in ds_hist.data_vars:\n",
    "            test = ~np.isnan(ds_hist[va].isel(time=slice(6, 9))).any().load()\n",
    "            assert test\n",
    "\n",
    "        bin_timeseries = ds_hist.bin_count.sum([di for di in ds_hist.bin_count.dims if di != 'time'])\n",
    "        bin_timeseries = bin_timeseries.isel(time=slice(0,5)).load()\n",
    "        assert (bin_timeseries > 10).all('time')\n",
    "\n",
    "    # only save annual summed values\n",
    "    ds_hist = ds_hist.coarsen(time=12).mean()\n",
    "\n",
    "    path = ofolder.joinpath(f\"{cmip6_dataset_id(ds_hist)}.zarr\")\n",
    "    print(path)\n",
    "\n",
    "    if not zarr_exists(path) or overwrite or (len(xr.open_zarr(path).time) != len(ds_hist.time)):\n",
    "        print(f\"{ds_hist.nbytes/1e9} GB\")\n",
    "        split = 5 if 'GFDL' in ds.source_id else 10\n",
    "        append_write_zarr(ds_hist, path, split)  # I got CM4 to run with 2.\n",
    "    else:\n",
    "        print(\"Exists already\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583f94dc",
   "metadata": {},
   "source": [
    "## Process the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8971e2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:     (x: 360, y: 180, lev: 33, bnds: 2)\n",
      "Coordinates:\n",
      "  * x           (x) float64 0.5 1.5 2.5 3.5 4.5 ... 356.5 357.5 358.5 359.5\n",
      "  * y           (y) float64 -89.5 -88.5 -87.5 -86.5 ... 86.5 87.5 88.5 89.5\n",
      "  * lev         (lev) float64 0.0 10.0 20.0 30.0 ... 4e+03 4.5e+03 5e+03 5.5e+03\n",
      "    lev_bounds  (lev, bnds) float64 ...\n",
      "    lon         (x, y) float64 0.5 0.5 0.5 0.5 0.5 ... 359.5 359.5 359.5 359.5\n",
      "    lat         (x, y) float64 -89.5 -88.5 -87.5 -86.5 ... 86.5 87.5 88.5 89.5\n",
      "Dimensions without coordinates: bnds\n",
      "Data variables:\n",
      "    TIME_bnds   (bnds) float64 165.7 196.0\n",
      "    o2          (lev, y, x) float32 nan nan nan nan nan ... nan nan nan nan nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/GEOCLIM/LRGROUP/jbusecke/projects/cmip6_omz/cmip6_omz/datasets.py:35: UserWarning: No bounds found for lon and lat. Reconstructing with a very simplified method. Check results carefully.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x7f51fd852eb0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cmip6_omz.datasets import load_bianchi\n",
    "from cmip6_omz.upstream_stash import construct_static_dz\n",
    "\n",
    "ds_obs = load_bianchi()#\n",
    "ds_obs = construct_static_dz(ds_obs, bound_coord='lev_bounds').rename({'thkcello':'dz_t'})# why TF is this not working in the function?\n",
    "\n",
    "ds_obs_hist = full_wrapper(ds_obs)\n",
    "\n",
    "path = ofolder.joinpath(f\"obs.zarr\")\n",
    "ds_obs_hist.to_zarr(path, consolidated=True, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3368bad",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4067800170.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_195671/4067800170.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    stop here\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "stop here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bcc57a",
   "metadata": {},
   "source": [
    "## Test the output against something I know\n",
    "\n",
    "This seems fine. The bin count is not exact, but that is probably due to some changes in the numerical precision in one of the methods.\n",
    "\n",
    "Nice the mean tracer values also line up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d68b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# might need to rename a few here so that it works and the dataset should probably be synth \n",
    "# Then I can move this to the tests.\n",
    "\n",
    "# define mask bins\n",
    "mask_bins = np.arange(-0.5, 13.0, 1)# for now manual, but maybe there is a clever way to do this?\n",
    "mask_bins\n",
    "\n",
    "lat_bins = np.arange(-90, 91, 20)\n",
    "lat_bins\n",
    "\n",
    "lev_bins = np.arange(0, 7000, 500)\n",
    "lev_bins\n",
    "vol = (ds.dz_t*ds.areacello) \n",
    "\n",
    "count = histogram(ds.o2, ds.lat, mask, bins=[o2_bins_converted, lat_bins, mask_bins], dim=['x','y'])\n",
    "volume = histogram(ds.o2, ds.lat, mask, bins=[o2_bins_converted, lat_bins, mask_bins], weights=vol, dim=['x','y'])\n",
    "tracers = {}\n",
    "for tr in ds.data_vars:\n",
    "    tracers[tr] = histogram(ds.o2, ds.lat, mask, bins=[o2_bins_converted, lat_bins, mask_bins], weights=ds[tr]*vol, dim=['x','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d9d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmip6_omz.omz_tools import mask_basin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fb0a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected_threshold = 0.082\n",
    "cutoff = o2_bins_converted[-1]\n",
    "test_full_pacific = test\n",
    "# expected_full_pacific = mask_basin(ds.o2.isel(time=0), drop=False)\n",
    "expected_full_pacific = ds.o2\n",
    "expected_full_pacific = xr.ones_like(expected_full_pacific).where(expected_full_pacific<=cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2655e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0c3abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_full_pacific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe237c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.o2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963fb740",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_full_pacific.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c70b77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_full_pacific.sum().data/expected_full_pacific.sum().load().data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d870807",
   "metadata": {},
   "source": [
    "I suspect this is due to the numerial precision going wrong somewhere..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38a0b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf33ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example with masked basin\n",
    "cutoff = o2_bins_converted[-3]\n",
    "test_full_pacific = test.sel(basin_mask_bin=slice(1.5, 3.5))\n",
    "expected_full_pacific = mask_basin(ds.o2, drop=False)\n",
    "expected_full_pacific = xr.ones_like(expected_full_pacific).where(expected_full_pacific<=cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0992c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_full_pacific.sum().data/expected_full_pacific.sum().load().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2719e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example with masked basin\n",
    "cutoff = o2_bins_converted[-3]\n",
    "test_full_pacific = test3.sel(basin_mask_bin=slice(1.5, 3.5)).sum()/test2.sel(basin_mask_bin=slice(1.5, 3.5)).sum()\n",
    "expected_full_pacific = mask_basin(ds, drop=False)\n",
    "expected_full_pacific = expected_full_pacific.where(expected_full_pacific<=cutoff)\n",
    "expected_full_pacific = expected_full_pacific.o2.weighted((expected_full_pacific.areacello*expected_full_pacific.dz_t).fillna(0)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646a4613",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_full_pacific.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf7c45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_full_pacific"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda_tigressdata-cmip6_omz]",
   "language": "python",
   "name": "conda-env-conda_tigressdata-cmip6_omz-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
